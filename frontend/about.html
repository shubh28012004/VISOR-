<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>About • VISOR</title>
  <link rel="stylesheet" href="./styles.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
</head>
<body>
  <header>
    <h1>About VISOR</h1>
    <p>How to use this AI-Powered Guiding Shield for Vision</p>
  </header>

  <main style="padding:16px 24px; max-width:900px; margin:0 auto;">
    <section class="panel">
      <div class="stat"><strong>Getting started</strong>
        <p>
          1) Click <em>Start Camera</em> and allow camera (and mic if you plan to ask by voice).<br/>
          2) You will see detections, a caption, and optional VQA answer on the right.<br/>
          3) Turn on <em>Speak captions</em> to hear a spoken summary. Use headphones for best results.
        </p>
      </div>

      <div class="stat"><strong>Asking questions (VQA)</strong>
        <p>
          - Toggle <em>Enable VQA</em> and type a question, or click <em>Ask</em> to speak it.<br/>
          - Turn on <em>Speak VQA answers</em> to hear the answer automatically.<br/>
          - Tips: Use Chrome on <code>localhost</code>/HTTPS for the most reliable voice input.
        </p>
      </div>

      <div class="stat"><strong>Assistant vs Guide</strong>
        <p>
          - <em>Assistant mode</em>: calm summaries every ~5 seconds, prefixed by “Summary: …”.<br/>
          - <em>Guide me</em>: short, frequent obstacle cues every ~1.5 seconds, prefixed by “Guidance: …”.<br/>
          - When both are enabled, Assistant auto-pauses while Guide is speaking to avoid overlap.
        </p>
      </div>

      <div class="stat"><strong>Controls</strong>
        <p>
          - <em>Interval (ms)</em>: how often a frame is sent to the backend.<br/>
          - <em>Speak captions</em>: toggle spoken summaries on/off.<br/>
          - <em>Enable VQA</em>: attach the current question to each frame.<br/>
          - <em>Speak VQA answers</em>: voice out new answers when they change.<br/>
          - <em>Assistant mode</em>: periodic scene summaries.<br/>
          - <em>Guide me</em>: rapid obstacle guidance using detections.
        </p>
      </div>

      <div class="stat"><strong>Troubleshooting</strong>
        <p>
          - No voice input: ensure mic permission is granted and try Chrome on HTTPS/localhost.<br/>
          - Hearing your own voice: use headphones; the app mutes the camera stream and pauses TTS during voice input.<br/>
          - Stop not stopping: we abort in-flight requests; if it persists, refresh the page.
        </p>
      </div>

      <div class="stat"><strong>Model notes</strong>
        <p>
          The backend uses YOLO for detections, BLIP for captions/VQA, and a small reasoner for narratives. You can
          switch model variants via environment variables before launching the server (see README).
        </p>
      </div>

      <p style="margin-top:12px;">
        <a href="/ui" style="color:#7cc4ff; text-decoration:none;">← Back to VISOR</a>
      </p>
    </section>
  </main>

  <footer>
    <p>VISOR • <a href="/ui" style="color:#7cc4ff; text-decoration:none;">Home</a></p>
  </footer>
</body>
</html>

